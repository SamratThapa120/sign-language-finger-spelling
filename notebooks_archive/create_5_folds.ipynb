{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b56707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120165\n"
     ]
    }
   ],
   "source": [
    "ALL_FILENAMES = glob.glob( '../dataset/npy_data/*.npy')\n",
    "train_df = pd.read_csv(\"../dataset/train.csv\")\n",
    "supp_df = pd.read_csv(\"../dataset/supplemental_metadata.csv\")\n",
    "\n",
    "print(len(ALL_FILENAMES))\n",
    "usable_names = set()\n",
    "for n in ALL_FILENAMES:\n",
    "    usable_names.add(os.path.split(n)[-1])\n",
    "gkf = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonnull = []\n",
    "for file,sequence_phrase in tqdm(zip(difficult.files,difficult.labels)):\n",
    "    path_to_sign = f\"../dataset/npy_data/{file}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8818d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from signet.configs.base import Base\n",
    "CFG = Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1221d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120165/120165 [02:14<00:00, 892.51it/s]\n"
     ]
    }
   ],
   "source": [
    "all_nan = {}\n",
    "seq_length = {}\n",
    "nonnullhand_length = {}\n",
    "for fpth in tqdm(ALL_FILENAMES):\n",
    "    npy = np.load(fpth)\n",
    "    if np.isfinite(npy).mean()==1:\n",
    "        all_nan[os.path.split(fpth)[-1].split(\".\")[0]] = 0\n",
    "    name=os.path.split(fpth)[-1].split(\".\")[0]\n",
    "    seq_length[name] = len(npy)\n",
    "    nonnullhand_length[name] = (np.isnan(npy[:,CFG.LHAND+CFG.RHAND].reshape(len(npy),-1)).mean(1)!=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61c659f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def parse_example(example_proto):\n",
    "    # Define the features within the example\n",
    "    feature_description = {\n",
    "        'coordinates': tf.io.FixedLenFeature([], tf.string),\n",
    "        'sequence_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sign': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    # Decode the coordinates\n",
    "    coordinates = tf.io.decode_raw(parsed_example['coordinates'], tf.float32)\n",
    "\n",
    "    # The 'sign' feature is a variable length feature, we have to convert it from sparse to dense\n",
    "    sign = tf.sparse.to_dense(parsed_example['sign'])\n",
    "    \n",
    "    return coordinates, parsed_example['sequence_id'], sign\n",
    "def process_tfrecord_file(tfrecord_name):\n",
    "    # Load the data from the TFRecord file\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name, compression_type='GZIP')\n",
    "\n",
    "    # Parse the data\n",
    "    parsed_dataset = raw_dataset.map(parse_example)\n",
    "    \n",
    "    for coordinates, seqid, sign in parsed_dataset:\n",
    "        # process data here\n",
    "\n",
    "        # Note: To convert tensors back to numpy use `.numpy()`\n",
    "        # e.g., `numpy_seqid = seqid.numpy()`\n",
    "        # print(f\"Coordinates: {coordinates.numpy().shape}\")\n",
    "        # print(f\"Seqid: {seqid}\")\n",
    "        # print(f\"Sign: {sign}\")\n",
    "        return coordinates.numpy().reshape(-1,543,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "668f3785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-22 05:01:39.673076: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(248, 543, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tfrecord_file(\"../dataset/tdf_data/1814394110.tfrecords\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a36004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38adef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(seq_length,open(\"../dataset/folds/seqlen.json\",\"w\"))\n",
    "# json.dump(all_nan,open(\"../dataset/folds/allnan.json\",\"w\"))\n",
    "json.dump({k:int(v) for k,v in nonnullhand_length.items()},open(\"../dataset/folds/handnotnull.json\",\"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8e0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"seqlen\"] = train_df.sequence_id.apply(lambda x: seq_length[str(x)])\n",
    "train_df[\"nonullhand\"] = train_df.sequence_id.apply(lambda x: nonnullhand_length[str(x)])\n",
    "train_df[\"labellen\"] = train_df.phrase.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e23e9937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>file_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>phrase</th>\n",
       "      <th>seqlen</th>\n",
       "      <th>nonullhand</th>\n",
       "      <th>labellen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816796431</td>\n",
       "      <td>217</td>\n",
       "      <td>3 creekhouse</td>\n",
       "      <td>123</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816825349</td>\n",
       "      <td>107</td>\n",
       "      <td>scales/kuhaylah</td>\n",
       "      <td>127</td>\n",
       "      <td>63</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816909464</td>\n",
       "      <td>1</td>\n",
       "      <td>1383 william lanier</td>\n",
       "      <td>236</td>\n",
       "      <td>178</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1816967051</td>\n",
       "      <td>63</td>\n",
       "      <td>988 franklin lane</td>\n",
       "      <td>102</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmarks/5414471.parquet</td>\n",
       "      <td>5414471</td>\n",
       "      <td>1817123330</td>\n",
       "      <td>89</td>\n",
       "      <td>6920 northeast 661st road</td>\n",
       "      <td>248</td>\n",
       "      <td>207</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67203</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388192924</td>\n",
       "      <td>88</td>\n",
       "      <td>431-366-2913</td>\n",
       "      <td>126</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67204</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388225542</td>\n",
       "      <td>154</td>\n",
       "      <td>994-392-3850</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67205</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388232076</td>\n",
       "      <td>95</td>\n",
       "      <td>https://www.tianjiagenomes.com</td>\n",
       "      <td>310</td>\n",
       "      <td>122</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67206</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388235284</td>\n",
       "      <td>36</td>\n",
       "      <td>90 kerwood circle</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67207</th>\n",
       "      <td>train_landmarks/2118949241.parquet</td>\n",
       "      <td>2118949241</td>\n",
       "      <td>388332538</td>\n",
       "      <td>176</td>\n",
       "      <td>802 co 66b</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67208 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     path     file_id  sequence_id  \\\n",
       "0         train_landmarks/5414471.parquet     5414471   1816796431   \n",
       "1         train_landmarks/5414471.parquet     5414471   1816825349   \n",
       "2         train_landmarks/5414471.parquet     5414471   1816909464   \n",
       "3         train_landmarks/5414471.parquet     5414471   1816967051   \n",
       "4         train_landmarks/5414471.parquet     5414471   1817123330   \n",
       "...                                   ...         ...          ...   \n",
       "67203  train_landmarks/2118949241.parquet  2118949241    388192924   \n",
       "67204  train_landmarks/2118949241.parquet  2118949241    388225542   \n",
       "67205  train_landmarks/2118949241.parquet  2118949241    388232076   \n",
       "67206  train_landmarks/2118949241.parquet  2118949241    388235284   \n",
       "67207  train_landmarks/2118949241.parquet  2118949241    388332538   \n",
       "\n",
       "       participant_id                          phrase  seqlen  nonullhand  \\\n",
       "0                 217                    3 creekhouse     123          58   \n",
       "1                 107                 scales/kuhaylah     127          63   \n",
       "2                   1             1383 william lanier     236         178   \n",
       "3                  63               988 franklin lane     102          56   \n",
       "4                  89       6920 northeast 661st road     248         207   \n",
       "...               ...                             ...     ...         ...   \n",
       "67203              88                    431-366-2913     126          35   \n",
       "67204             154                    994-392-3850     176         176   \n",
       "67205              95  https://www.tianjiagenomes.com     310         122   \n",
       "67206              36               90 kerwood circle      45           9   \n",
       "67207             176                      802 co 66b      70           8   \n",
       "\n",
       "       labellen  \n",
       "0            12  \n",
       "1            15  \n",
       "2            19  \n",
       "3            17  \n",
       "4            25  \n",
       "...         ...  \n",
       "67203        12  \n",
       "67204        12  \n",
       "67205        30  \n",
       "67206        17  \n",
       "67207        10  \n",
       "\n",
       "[67208 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0c6418c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7585852874657779"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((train_df.seqlen>2*train_df.labellen)&(train_df.nonullhand>2*train_df.labellen)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc1da96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_df[\"seqlen\"] = supp_df.sequence_id.apply(lambda x: seq_length[str(x)] if str(x) in seq_length else 0)\n",
    "supp_df[\"nonullhand\"] = train_df.sequence_id.apply(lambda x: nonnullhand_length[str(x)] if str(x) in nonnullhand_length else 0)\n",
    "\n",
    "supp_df[\"labellen\"] = supp_df.phrase.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1101d749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5945088560746252"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((supp_df.seqlen>2*supp_df.labellen)&(supp_df.nonullhand>2*supp_df.labellen)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a548f5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "supp_df = supp_df[supp_df.seqlen>supp_df.labellen].reset_index(drop=True)\n",
    "train_df = train_df[train_df.seqlen>train_df.labellen].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db6cad5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64868, 51125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df),len(supp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8747b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([train_df,supp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0776fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4489be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.015246346426589381, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_df.seqlen>384).mean(),(all_df.labellen>45).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04754625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(all_df.sample(1000),x=[\"seqlen\",\"labellen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "206ba87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13053 51815\n"
     ]
    }
   ],
   "source": [
    "# a23+1\n",
    "for fold_idx,(train, test) in enumerate(gkf.split(train_df.sequence_id, groups=train_df.participant_id)):\n",
    "    valid_seqid = set()\n",
    "    for idx in test:\n",
    "        valid_seqid.add(train_df.sequence_id[idx])\n",
    "    train_info = []\n",
    "    valid_info = []\n",
    "    for seqid,label in zip(train_df.sequence_id,train_df.phrase):\n",
    "        fname = f\"{seqid}.npy\"\n",
    "        if fname in usable_names and seqid not in valid_seqid:\n",
    "            train_info.append((fname,label))\n",
    "    # for seqid,label in zip(supp_df.sequence_id,supp_df.phrase):\n",
    "    #     fname = f\"{seqid}.npy\"\n",
    "    #     if fname in usable_names:\n",
    "    #         train_info.append((fname,label))\n",
    "    train_info = pd.DataFrame(train_info,columns=[\"files\",\"labels\"])\n",
    "\n",
    "    for seqid,label in zip(train_df.sequence_id,train_df.phrase):\n",
    "        fname = f\"{seqid}.npy\"\n",
    "        if fname in usable_names and seqid in valid_seqid:\n",
    "            valid_info.append((fname,label))\n",
    "    valid_info = pd.DataFrame(valid_info,columns=[\"files\",\"labels\"])\n",
    "    print(len(valid_info),len(train_info))\n",
    "    train_info.to_csv(f\"../dataset/folds/foldtune_train.csv\",index=False)\n",
    "    valid_info.to_csv(f\"../dataset/folds/foldtune_valid.csv\",index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9bb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2413.090372,
   "end_time": "2023-03-23T16:43:55.112208",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-23T16:03:42.021836",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
